syntax = "proto3";

package voice;

import "google/protobuf/duration.proto";

service VoiceService {
    // Performs synchronous speech recognition on an audio file
    rpc SyncRecognize(SyncRecognizeRequest) returns (SyncRecognizeResponse) {}

    // Performs asynchronous speech recognition on an audio file
    rpc AsyncRecognize(AsyncRecognizeRequest) returns (AsyncRecognizeResponse) {}

    // Gets the status of an asynchronous recognition operation
    rpc GetAsyncRecognizeStatus(GetAsyncRecognizeStatusRequest) returns (GetAsyncRecognizeStatusResponse) {}

    // Performs bidirectional streaming speech recognition
    rpc StreamingRecognize(stream StreamingRecognizeRequest) returns (stream StreamingRecognizeResponse) {}
}

// Audio encoding types
enum AudioEncoding {
    ENCODING_UNSPECIFIED = 0;
    LINEAR16 = 1;  // PCM 16-bit
    FLAC = 2;
    MULAW = 3;
    AMR = 4;
    AMR_WB = 5;
    OGG_OPUS = 6;
    SPEEX_WITH_HEADER_BYTE = 7;
}

// Recognition config for all requests
message RecognitionConfig {
    AudioEncoding encoding = 1;
    int32 sample_rate_hertz = 2;  // Sample rate in Hertz
    string language_code = 3;     // BCP-47 language code, e.g. "en-US"
    int32 max_alternatives = 4;   // Maximum number of recognition alternatives
    bool profanity_filter = 5;    // Whether to filter out profanity
    repeated string speech_contexts = 6;  // List of phrases to boost recognition
    bool enable_word_time_offsets = 7;    // Whether to include word-level time offsets
    string model = 8;             // Which model to use
}

// Request for synchronous recognition
message SyncRecognizeRequest {
    RecognitionConfig config = 1;
    oneof audio_source {
        bytes audio_content = 2;  // The audio data bytes
        string uri = 3;          // URI of the audio file in GCS
    }
}

// Word-level timing info
message WordInfo {
    string word = 1;
    google.protobuf.Duration start_time = 2;
    google.protobuf.Duration end_time = 3;
}

// Alternative recognition hypothesis
message SpeechRecognitionAlternative {
    string transcript = 1;
    float confidence = 2;
    repeated WordInfo words = 3;
}

// Single recognition result
message SpeechRecognitionResult {
    repeated SpeechRecognitionAlternative alternatives = 1;
}

// Response for synchronous recognition
message SyncRecognizeResponse {
    repeated SpeechRecognitionResult results = 1;
}

// Request for asynchronous recognition
message AsyncRecognizeRequest {
    RecognitionConfig config = 1;
    oneof audio_source {
        bytes audio_content = 2;
        string uri = 3;
    }
    string request_id = 4;  // Client-provided request ID
}

// Response for asynchronous recognition
message AsyncRecognizeResponse {
    string request_id = 1;
    string operation_id = 2;
}

// Request to get async operation status
message GetAsyncRecognizeStatusRequest {
    string operation_id = 1;
}

// Response containing async operation status
message GetAsyncRecognizeStatusResponse {
    enum Status {
        UNKNOWN = 0;
        RUNNING = 1;
        SUCCEEDED = 2;
        FAILED = 3;
    }
    Status status = 1;
    repeated SpeechRecognitionResult results = 2;
    string error = 3;
}

// Config for streaming recognition
message StreamingRecognitionConfig {
    RecognitionConfig config = 1;
    bool single_utterance = 2;    // Stop after first utterance
    bool interim_results = 3;     // Return interim results
}

// Request message for streaming recognition
message StreamingRecognizeRequest {
    oneof streaming_request {
        StreamingRecognitionConfig streaming_config = 1;
        bytes audio_content = 2;
    }
}

// Streaming recognition result
message StreamingRecognitionResult {
    repeated SpeechRecognitionAlternative alternatives = 1;
    bool is_final = 2;           // Whether this is the final result
    float stability = 3;         // Stability of interim result
}

// Speech event types for streaming recognition
enum SpeechEventType {
    SPEECH_EVENT_UNSPECIFIED = 0;
    END_OF_SINGLE_UTTERANCE = 1;
}

// Response message for streaming recognition
message StreamingRecognizeResponse {
    repeated StreamingRecognitionResult results = 1;
    SpeechEventType speech_event_type = 2;
} 